# Emotion-Recognition

This project focuses on training computers to recognize emotions in educational videos by reannotating the DAiSEE dataset into categories like engagement, confusion, frustration, and boredom. Accurate emotion detection is crucial for adaptive educational tools that enhance learning outcomes, yet challenges like detecting subtle cues, class imbalance, and model overfitting persist. Leveraging advanced deep learning models—EfficientNet, Vision Transformer, and BiT—we aim to improve frame classification accuracy. Using OpenCV, we extract and analyze video frames for precise annotation. While showing promising results, future work includes integrating additional data types to deepen emotional insights, setting the stage for more effective educational technologies.

